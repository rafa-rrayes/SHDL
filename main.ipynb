{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8f378ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Tuple, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Port:\n",
    "    \"\"\"Represents an input or output port.\"\"\"\n",
    "    name: str\n",
    "    width: int = 1  # Number of bits (default 1 for single-bit)\n",
    "    is_input: bool = True\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Instance:\n",
    "    \"\"\"Represents a gate or component instance.\"\"\"\n",
    "    name: str\n",
    "    component_type: str\n",
    "    inputs: Dict[str, str] = field(default_factory=dict)  # port_name -> connected_signal\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Component:\n",
    "    \"\"\"Represents a SHDL component.\"\"\"\n",
    "    name: str\n",
    "    inputs: List[Port] = field(default_factory=list)\n",
    "    outputs: List[Port] = field(default_factory=list)\n",
    "    instances: List[Instance] = field(default_factory=list)\n",
    "    connections: List[Tuple[str, str]] = field(default_factory=list)  # (from, to)\n",
    "    imports: Dict[str, List[str]] = field(default_factory=dict)  # module -> [components]\n",
    "\n",
    "\n",
    "class SHDLParser:\n",
    "    \"\"\"Parser for SHDL files.\"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, search_paths: List[Path]):\n",
    "        self.search_paths = search_paths\n",
    "        self.components: Dict[str, Component] = {}\n",
    "        self.STDGATES = {\"AND\", \"OR\", \"NOT\", \"XOR\", \"NAND\", \"NOR\", \"XNOR\"}\n",
    "    \n",
    "        \n",
    "    def parse_file(self, filepath: Path) -> Component:\n",
    "        \"\"\"Parse a SHDL file and return the component.\"\"\"\n",
    "        content = filepath.read_text()\n",
    "        \n",
    "        # Remove comments\n",
    "        content = re.sub(r'#.*$', '', content, flags=re.MULTILINE)\n",
    "        \n",
    "        # Parse imports\n",
    "        imports = self._parse_imports(content)\n",
    "        \n",
    "        # Parse component declaration\n",
    "        comp = self._parse_component(content)\n",
    "        comp.imports = imports\n",
    "        \n",
    "        # Cache the component\n",
    "        self.components[comp.name] = comp\n",
    "        self.parent = comp.name\n",
    "        # Load imported components\n",
    "        self._load_imports(comp, filepath.parent)\n",
    "\n",
    "        return comp\n",
    "    \n",
    "    def _parse_imports(self, content: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"Parse import statements.\"\"\"\n",
    "        imports = {}\n",
    "        \n",
    "        # Match: use module::{Component1, Component2};\n",
    "        pattern = r'use\\s+(\\w+)\\s*::\\s*\\{([^}]+)\\}'\n",
    "        for match in re.finditer(pattern, content):\n",
    "            module = match.group(1)\n",
    "            components_str = match.group(2)\n",
    "            components = [c.strip() for c in components_str.split(',')]\n",
    "            imports[module] = components\n",
    "            \n",
    "        return imports\n",
    "    \n",
    "    def _parse_component(self, content: str) -> Component:\n",
    "        \"\"\"Parse component declaration.\"\"\"\n",
    "        # Match: component Name(inputs) -> (outputs) { ... }\n",
    "        pattern = r'component\\s+(\\w+)\\s*\\(([^)]*)\\)\\s*->\\s*\\(([^)]*)\\)\\s*\\{(.*)\\}'\n",
    "        match = re.search(pattern, content, re.DOTALL)\n",
    "        \n",
    "        if not match:\n",
    "            raise ValueError(\"Invalid component declaration\")\n",
    "        \n",
    "        comp_name = match.group(1)\n",
    "        inputs_str = match.group(2)\n",
    "        outputs_str = match.group(3)\n",
    "        body = match.group(4)\n",
    "        \n",
    "        comp = Component(name=comp_name)\n",
    "        \n",
    "        # Parse inputs\n",
    "        comp.inputs = self._parse_ports(inputs_str, is_input=True)\n",
    "        \n",
    "        # Parse outputs\n",
    "        comp.outputs = self._parse_ports(outputs_str, is_input=False)\n",
    "        \n",
    "        # Parse body (instances and connections)\n",
    "        self._parse_body(comp, body)\n",
    "        \n",
    "        return comp\n",
    "    \n",
    "    def _parse_ports(self, ports_str: str, is_input: bool) -> List[Port]:\n",
    "        \"\"\"Parse port declarations.\"\"\"\n",
    "        ports = []\n",
    "        \n",
    "        if not ports_str.strip():\n",
    "            return ports\n",
    "        \n",
    "        for port_decl in ports_str.split(','):\n",
    "            port_decl = port_decl.strip()\n",
    "            if not port_decl:\n",
    "                continue\n",
    "            \n",
    "            # Check for bit width: Name[16]\n",
    "            match = re.match(r'(\\w+)\\[(\\d+)\\]', port_decl)\n",
    "            if match:\n",
    "                name = match.group(1)\n",
    "                width = int(match.group(2))\n",
    "                ports.append(Port(name=name, width=width, is_input=is_input))\n",
    "            else:\n",
    "                # Single-bit port\n",
    "                ports.append(Port(name=port_decl, width=1, is_input=is_input))\n",
    "        \n",
    "        return ports\n",
    "    \n",
    "    def _parse_body(self, comp: Component, body: str):\n",
    "        \"\"\"Parse component body (instances and connections).\"\"\"\n",
    "        # Expand generators first\n",
    "        body = self._expand_generators(body)\n",
    "        \n",
    "        # Split into instances and connections\n",
    "        connect_match = re.search(r'connect\\s*\\{(.*)\\}', body, re.DOTALL)\n",
    "        \n",
    "        if connect_match:\n",
    "            instances_part = body[:connect_match.start()]\n",
    "            connections_part = connect_match.group(1)\n",
    "        else:\n",
    "            instances_part = body\n",
    "            connections_part = \"\"\n",
    "        \n",
    "        # Parse instances\n",
    "        self._parse_instances(comp, instances_part)\n",
    "        \n",
    "        # Parse connections\n",
    "        self._parse_connections(comp, connections_part)\n",
    "    \n",
    "    def _expand_generators(self, body: str) -> str:\n",
    "        \"\"\"Expand generator syntax:\n",
    "        >i[2, 16]{ ... use {i}, {i-1}, {i+1}, etc. ... }\n",
    "        >k[8]{ ... }\n",
    "        \"\"\"\n",
    "        def expand_generator(match):\n",
    "            var = match.group(1)      # e.g., \"i\"\n",
    "            range_spec = match.group(2)\n",
    "            content = match.group(3)\n",
    "\n",
    "            # Parse range: either \"N\" or \"start, end\"\n",
    "            if ',' in range_spec:\n",
    "                start_str, end_str = range_spec.split(',')\n",
    "                start = int(start_str.strip())\n",
    "                end = int(end_str.strip())\n",
    "            else:\n",
    "                start = 1\n",
    "                end = int(range_spec.strip())\n",
    "\n",
    "            result_chunks = []\n",
    "\n",
    "            # For each iteration bind var to i and expand {<expr using var>}\n",
    "            for i in range(start, end + 1):\n",
    "                def eval_braced_expr(m):\n",
    "                    expr = m.group(1).strip()\n",
    "                    # Allow only the loop var name (var) as 'i' in the expression.\n",
    "                    # We map whatever the loop variable is to the name 'i' for simplicity.\n",
    "                    # This lets \"{i-1}\" work regardless of the chosen variable name.\n",
    "                    try:\n",
    "                        value = eval(expr, {\"__builtins__\": None}, {\"i\": i})\n",
    "                    except Exception as e:\n",
    "                        raise ValueError(f\"Invalid generator expression '{{{expr}}}' \"\n",
    "                                        f\"with {var}={i}: {e}\")\n",
    "                    # Normalize ints/floats to string\n",
    "                    if isinstance(value, float) and value.is_integer():\n",
    "                        value = int(value)\n",
    "                    return str(value)\n",
    "\n",
    "                # Replace ALL {...} occurrences (names, indices, signal labels, etc.)\n",
    "                expanded = re.sub(r'\\{([^{}]+)\\}', eval_braced_expr, content)\n",
    "                result_chunks.append(expanded)\n",
    "\n",
    "            return '\\n'.join(result_chunks)\n",
    "\n",
    "        # Keep expanding until no more generators (handle multiple generators in the body)\n",
    "        prev_body = None\n",
    "        max_iterations = 10\n",
    "        iteration = 0\n",
    "        while prev_body != body and iteration < max_iterations:\n",
    "            prev_body = body\n",
    "            body = re.sub(\n",
    "                r'>\\s*(\\w+)\\[([^\\]]+)\\]\\s*\\{((?:[^{}]|\\{[^{}]*\\})*)\\}',\n",
    "                expand_generator,\n",
    "                body,\n",
    "                count=1,\n",
    "                flags=re.MULTILINE | re.DOTALL\n",
    "            )\n",
    "            iteration += 1\n",
    "\n",
    "        return body\n",
    "\n",
    "    \n",
    "    def _parse_instances(self, comp: Component, instances_str: str):\n",
    "        \"\"\"Parse instance declarations.\"\"\"\n",
    "        # Match: name: Type;\n",
    "        pattern = r'(\\w+)\\s*:\\s*(\\w+)\\s*;'\n",
    "        \n",
    "        for match in re.finditer(pattern, instances_str):\n",
    "            name = match.group(1)\n",
    "            comp_type = match.group(2)\n",
    "            comp.instances.append(Instance(name=name, component_type=comp_type))\n",
    "    \n",
    "    def _parse_connections(self, comp: Component, connections_str: str):\n",
    "        \"\"\"Parse connection statements.\"\"\"\n",
    "        # Match: signal -> port;\n",
    "        pattern = r'([^\\s;]+)\\s*->\\s*([^\\s;]+)\\s*;'\n",
    "        \n",
    "        for match in re.finditer(pattern, connections_str):\n",
    "            from_sig = match.group(1).strip()\n",
    "            to_sig = match.group(2).strip()\n",
    "            comp.connections.append((from_sig, to_sig))\n",
    "    \n",
    "    def _load_imports(self, comp: Component, base_path: Path):\n",
    "        \"\"\"Load imported components from files.\"\"\"\n",
    "        for module, components in comp.imports.items():\n",
    "            if module == \"stdgates\":\n",
    "                continue  # Standard gates are built-in\n",
    "            \n",
    "            # Try to find the module file\n",
    "            for search_path in [base_path] + self.search_paths:\n",
    "                module_file = search_path / f\"{module}.shdl\"\n",
    "                if module_file.exists():\n",
    "                    imported_comp = self.parse_file(module_file)\n",
    "                    break\n",
    "\n",
    "\n",
    "    def flatten_component(self, parent: Component) -> Component:\n",
    "        \"\"\"\n",
    "        Flatten the given component by inlining all instances of certain target component types.\n",
    "        \"\"\"\n",
    "\n",
    "        # --- Helpers -------------------------------------------------------------\n",
    "\n",
    "        def ports_of(defn: \"Component\"):\n",
    "            return {p.name for p in defn.inputs}, {p.name for p in defn.outputs}\n",
    "\n",
    "        def output_drivers(defn: \"Component\"):\n",
    "            \"\"\"\n",
    "            Map child output port -> internal driver pin (e.g., 'Sum' -> 'x2.O').\n",
    "            \"\"\"\n",
    "            m = {}\n",
    "            for src, dst in defn.connections:\n",
    "                if '.' not in dst:  # bare output port\n",
    "                    m[dst] = src\n",
    "            return m\n",
    "\n",
    "        def prefixed_internal(pin: str, inst_name: str):\n",
    "            \"\"\"\n",
    "            Prefix internal instance pins: 'x1.O' -> 'fa1_x1.O'.\n",
    "            Leave bare ports ('A', 'Sum') unchanged (handled elsewhere).\n",
    "            \"\"\"\n",
    "            if '.' in pin:\n",
    "                inst, port = pin.split('.', 1)\n",
    "                return f\"{inst_name}_{inst}.{port}\"\n",
    "            return pin\n",
    "\n",
    "        def is_abstract_pin(token: str):\n",
    "            # an abstract pin looks like 'fa1.Cin' or 'fa1.Cout'\n",
    "            return '.' in token and '[' not in token and token.count('.') == 1\n",
    "\n",
    "        # Index original connections\n",
    "        conns_from = defaultdict(list)\n",
    "        conns_to   = defaultdict(list)\n",
    "        for c in parent.connections:\n",
    "            s, d = c\n",
    "            conns_from[s].append(c)\n",
    "            conns_to[d].append(c)\n",
    "\n",
    "        # Identify instances to inline and keep the rest\n",
    "        instances_to_inline = [inst for inst in parent.instances if inst.component_type not in self.STDGATES]\n",
    "        new_instances = [inst for inst in parent.instances if inst.component_type in self.STDGATES]\n",
    "        new_connections = []\n",
    "\n",
    "        # Prepare import merging (and later clean-up of now-unused target symbols)\n",
    "        merged_imports = deepcopy(getattr(parent, \"imports\", {}))\n",
    "\n",
    "        # Build per-instance metadata for all children that will be inlined\n",
    "        inlined_meta = {}  # inst_name -> dict(...)\n",
    "        for inst in instances_to_inline:\n",
    "            child_def = self.components[inst.component_type]\n",
    "            in_ports, out_ports = ports_of(child_def)\n",
    "            out_drv = output_drivers(child_def)\n",
    "            inlined_meta[inst.name] = {\n",
    "                \"def\": child_def,\n",
    "                \"in_ports\": in_ports,\n",
    "                \"out_ports\": out_ports,\n",
    "                \"out_drivers\": out_drv,\n",
    "            }\n",
    "\n",
    "        # Global maps for substitution\n",
    "        # (1) Abstract OUTPUT -> concrete internal driver pin (prefixed)\n",
    "        abstract_out_to_driver = {}\n",
    "        for inst in instances_to_inline:\n",
    "            meta = inlined_meta[inst.name]\n",
    "            for outp, driver_pin in meta[\"out_drivers\"].items():\n",
    "                abstract = f\"{inst.name}.{outp}\"               # e.g., 'fa1.Cout'\n",
    "                concrete = prefixed_internal(driver_pin, inst.name)  # 'fa1_o1.O'\n",
    "                abstract_out_to_driver[abstract] = concrete\n",
    "\n",
    "        def resolve_output_ref(token: str) -> str:\n",
    "            \"\"\"Replace 'inst.OutPort' with its internal driver pin, repeatedly if needed.\"\"\"\n",
    "            while token in abstract_out_to_driver:\n",
    "                token = abstract_out_to_driver[token]\n",
    "            return token\n",
    "\n",
    "        # (2) Abstract INPUT -> resolved external net (after output resolution)\n",
    "        abstract_in_to_net = {}\n",
    "        for inst in instances_to_inline:\n",
    "            meta = inlined_meta[inst.name]\n",
    "            for inp in meta[\"in_ports\"]:\n",
    "                abs_input = f\"{inst.name}.{inp}\"  # e.g., 'fa2.Cin'\n",
    "                if abs_input in conns_to and conns_to[abs_input]:\n",
    "                    upstream = conns_to[abs_input][-1][0]  # last writer wins\n",
    "                    upstream = resolve_output_ref(upstream)  # resolve if it was 'faX.Out'\n",
    "                    abstract_in_to_net[abs_input] = upstream\n",
    "                else:\n",
    "                    # Unconnected input; leave unmapped. (Could default/raise as needed.)\n",
    "                    pass\n",
    "\n",
    "        def resolve_input_ref(token: str) -> str:\n",
    "            \"\"\"Replace 'inst.InPort' with its resolved external net, repeatedly if needed.\"\"\"\n",
    "            seen = set()\n",
    "            while token in abstract_in_to_net and token not in seen:\n",
    "                seen.add(token)\n",
    "                token = abstract_in_to_net[token]\n",
    "                token = resolve_output_ref(token)\n",
    "            return token\n",
    "\n",
    "        # Helper: is the destination an abstract INPUT of another inlined child?\n",
    "        def is_inlined_abstract_input(dst: str) -> bool:\n",
    "            if not is_abstract_pin(dst):\n",
    "                return False\n",
    "            inst_name, port = dst.split('.', 1)\n",
    "            if inst_name not in inlined_meta:\n",
    "                return False\n",
    "            return port in inlined_meta[inst_name][\"in_ports\"]\n",
    "\n",
    "        # Bring in internals for each inlined child\n",
    "        for inst in instances_to_inline:\n",
    "            meta = inlined_meta[inst.name]\n",
    "            child_def = meta[\"def\"]\n",
    "\n",
    "            # (a) Add internal instances with prefix\n",
    "            for cinst in child_def.instances:\n",
    "                renamed = deepcopy(cinst)\n",
    "                renamed.name = f\"{inst.name}_{cinst.name}\"\n",
    "                new_instances.append(renamed)\n",
    "\n",
    "            # (b) Merge child's imports\n",
    "            if getattr(child_def, \"imports\", None):\n",
    "                for lib, syms in child_def.imports.items():\n",
    "                    merged_imports.setdefault(lib, [])\n",
    "                    for s in syms:\n",
    "                        if s not in merged_imports[lib]:\n",
    "                            merged_imports[lib].append(s)\n",
    "\n",
    "            # (c) Recreate child's internal wiring with substitutions:\n",
    "            #     - child input ports -> resolved external net (input map)\n",
    "            #     - internal pins -> prefixed_internal(...)\n",
    "            #     - child output ports are NOT emitted as ports (we wire their drivers elsewhere)\n",
    "            input_external = {p: abstract_in_to_net.get(f\"{inst.name}.{p}\") for p in meta[\"in_ports\"]}\n",
    "\n",
    "            for src, dst in child_def.connections:\n",
    "                # Resolve source\n",
    "                if '.' not in src:  # child input port\n",
    "                    upstream = input_external.get(src)\n",
    "                    if upstream is None:\n",
    "                        # Skip unconnected; or raise if strict is desired\n",
    "                        continue\n",
    "                    flat_src = resolve_output_ref(upstream)\n",
    "                else:\n",
    "                    flat_src = prefixed_internal(src, inst.name)\n",
    "\n",
    "                # Resolve destination\n",
    "                if '.' not in dst:\n",
    "                    # Child output port: skip here — parent edges will be created below\n",
    "                    continue\n",
    "                else:\n",
    "                    flat_dst = prefixed_internal(dst, inst.name)\n",
    "                    new_connections.append((flat_src, flat_dst))\n",
    "\n",
    "            # (d) Rewire parent edges that referenced child OUTPUTS (e.g., 'fa1.Cout' -> X)\n",
    "            #     But do NOT create edges into abstract inputs of other inlined children\n",
    "            #     (those will be realized by that child's own internal wiring above).\n",
    "            for outp in meta[\"out_ports\"]:\n",
    "                abs_out = f\"{inst.name}.{outp}\"\n",
    "                if abs_out not in conns_from:\n",
    "                    continue\n",
    "                driver = resolve_output_ref(abs_out)  # should give prefixed internal pin\n",
    "                for (_src, dst) in conns_from[abs_out]:\n",
    "                    if is_inlined_abstract_input(dst):\n",
    "                        # Skip; the receiving child will handle via its internal mapping.\n",
    "                        continue\n",
    "                    # Otherwise, we can keep the destination:\n",
    "                    new_connections.append((driver, dst))\n",
    "\n",
    "        # Keep original parent connections that don't touch any abstract pins of inlined children\n",
    "        abstract_pins = set()\n",
    "        for inst in instances_to_inline:\n",
    "            meta = inlined_meta[inst.name]\n",
    "            for p in meta[\"in_ports\"] | meta[\"out_ports\"]:\n",
    "                abstract_pins.add(f\"{inst.name}.{p}\")\n",
    "\n",
    "        def touches_any_abstract(conn):\n",
    "            s, d = conn\n",
    "            return (s in abstract_pins) or (d in abstract_pins)\n",
    "\n",
    "        for conn in parent.connections:\n",
    "            if not touches_any_abstract(conn):\n",
    "                new_connections.append(conn)\n",
    "\n",
    "        # Final sweep: substitute any leftover abstract references on either side\n",
    "        finalized = []\n",
    "        for s, d in new_connections:\n",
    "            s2 = resolve_output_ref(s)\n",
    "            s2 = resolve_input_ref(s2)   # just in case a chain pointed to an abstract input\n",
    "            d2 = resolve_output_ref(d)   # unlikely for destinations, but safe\n",
    "            d2 = resolve_input_ref(d2)\n",
    "            # Drop any connection that still targets an abstract input (shouldn't happen)\n",
    "            if is_inlined_abstract_input(d2):\n",
    "                continue\n",
    "            finalized.append((s2, d2))\n",
    "\n",
    "        # Optional: prune imports of fully inlined component types (e.g., 'FullAdder')\n",
    "        if merged_imports:\n",
    "            cleaned_imports = {}\n",
    "            for lib, syms in merged_imports.items():\n",
    "                kept = [s for s in syms if s in self.STDGATES]\n",
    "                if kept:\n",
    "                    cleaned_imports[lib] = kept\n",
    "            merged_imports = cleaned_imports\n",
    "\n",
    "        # Commit\n",
    "        parent.instances = new_instances\n",
    "        parent.connections = finalized\n",
    "        parent.imports = merged_imports\n",
    "        return parent\n",
    "    def flatten_all_levels(self, parent, max_passes=64):\n",
    "        \"\"\"\n",
    "        Repeatedly inline until no instances of target_types remain,\n",
    "        or until max_passes is reached (to avoid accidental cycles).\n",
    "        \"\"\"\n",
    "        def count_targets(c):\n",
    "            return sum(1 for i in c.instances if i.component_type not in self.STDGATES)\n",
    "\n",
    "        for _ in range(max_passes):\n",
    "            before = count_targets(parent)\n",
    "            if before == 0:\n",
    "                # return parent\n",
    "                pass\n",
    "            self.flatten_component(parent)\n",
    "            after = count_targets(parent)\n",
    "            if after >= before:\n",
    "                # No progress; likely cyclic or missing defs — bail out safely.\n",
    "                # return parent\n",
    "                pass\n",
    "        return parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6d23eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_c_bitpacked(component):\n",
    "    \"\"\"\n",
    "    Generate a fast, bit-packed, registered C simulator for the given netlist.\n",
    "\n",
    "    Assumptions:\n",
    "      - component.inputs / outputs: list of Ports (name:str, width:int, is_input:bool)\n",
    "      - component.instances: list of Instances (name:str, component_type:str, inputs:dict unused)\n",
    "      - component.connections: list of (src:str, dst:str), where src/dst are tokens like:\n",
    "          * 'A[3]' or scalar 'clk' for top inputs\n",
    "          * 'Out[7]' for top outputs (only as dest)\n",
    "          * 'instName.pin' for instance pins; pin names are 'A','B' (binary ops) or 'A' (unary NOT)\n",
    "          * 'instName.O' is the output pin (used only as source)\n",
    "    Timing:\n",
    "      - Every instance output 'inst.O' is a 1-cycle registered state.\n",
    "      - tick() computes next state n.* from snapshot (previous state + current inputs), then commit.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- helpers ----------\n",
    "    def c_ident(s):\n",
    "        s = s.replace('.', '_')\n",
    "        s = s.replace('[', '_').replace(']', '')\n",
    "        s = re.sub(r'[^a-zA-Z0-9_]', '_', s)\n",
    "        if re.match(r'^[0-9]', s):\n",
    "            s = '_' + s\n",
    "        return s\n",
    "\n",
    "    def is_bit(ref):\n",
    "        return bool(re.match(r'^[A-Za-z_]\\w*\\[\\d+\\]$', ref))\n",
    "\n",
    "    def parse_bit(ref):\n",
    "        m = re.match(r'^([A-Za-z_]\\w*)\\[(\\d+)\\]$', ref)\n",
    "        if not m:\n",
    "            raise ValueError(f'Not a bit ref: {ref}')\n",
    "        return m.group(1), int(m.group(2))\n",
    "\n",
    "    def is_inst_pin(ref):\n",
    "        return bool(re.match(r'^[A-Za-z_]\\w*\\.[A-Za-z_]\\w*$', ref))\n",
    "\n",
    "    def split_inst_pin(ref):\n",
    "        m = re.match(r'^([A-Za-z_]\\w*)\\.([A-Za-z_]\\w*)$', ref)\n",
    "        if not m:\n",
    "            raise ValueError(f'Not an instance pin: {ref}')\n",
    "        return m.group(1), m.group(2)\n",
    "\n",
    "    # ---------- model digest ----------\n",
    "    inputs = {p.name: p for p in component.inputs if p.is_input}\n",
    "    outputs = {p.name: p for p in component.outputs if not p.is_input}\n",
    "    insts = {i.name: i for i in component.instances}\n",
    "\n",
    "    # map: type -> ordered list of instance names (lane order)\n",
    "    type_to_insts = defaultdict(list)\n",
    "    for i in component.instances:\n",
    "        type_to_insts[i.component_type].append(i.name)\n",
    "    # lane index per instance: inst_name -> (type, chunk_idx, lane_within_chunk)\n",
    "    inst_lane = {}\n",
    "    type_chunks = {}  # type -> number of 64-bit chunks needed\n",
    "    for t, lst in type_to_insts.items():\n",
    "        num_chunks = (len(lst) + 63) // 64  # ceiling division\n",
    "        type_chunks[t] = num_chunks\n",
    "        for lane, name in enumerate(lst):\n",
    "            chunk_idx = lane // 64\n",
    "            lane_in_chunk = lane % 64\n",
    "            inst_lane[name] = (t, chunk_idx, lane_in_chunk)\n",
    "\n",
    "    # Collect per-instance input pin wiring: inst -> {pin: src_token}\n",
    "    pin_wires = defaultdict(dict)\n",
    "    # Collect top-level output bit drivers: 'Out[3]' -> src_token\n",
    "    out_src = {}\n",
    "\n",
    "    for src, dst in component.connections:\n",
    "        if is_inst_pin(dst):\n",
    "            i, pin = split_inst_pin(dst)\n",
    "            pin_wires[i][pin] = src\n",
    "        else:\n",
    "            # must be top-level output bit or scalar\n",
    "            if dst in outputs:\n",
    "                out_src[f'{dst}[1]'] = src\n",
    "            else:\n",
    "                out_src[dst] = src\n",
    "\n",
    "    # Gate pin sets (per primitive)\n",
    "    BIN_OP = {\n",
    "        'AND': '&',\n",
    "        'OR':  '|',\n",
    "        'XOR': '^',\n",
    "        'NAND': None,  # computed as ~(A & B)\n",
    "        'NOR':  None,  # computed as ~(A | B)\n",
    "    }\n",
    "    UNI_OP = {\n",
    "        'NOT': None,   # computed as ~A\n",
    "    }\n",
    "    supported_types = set(BIN_OP) | set(UNI_OP)\n",
    "    for i in component.instances:\n",
    "        if i.component_type not in supported_types:\n",
    "            raise ValueError(f\"Unsupported gate type: {i.component_type}\")\n",
    "\n",
    "    # For each (type, chunk, pin, source_token) build a 64-bit mask\n",
    "    masks = defaultdict(int)  # key = (type, chunk_idx, pin, source_token) -> uint64 mask\n",
    "    type_chunk_active_mask = defaultdict(int)  # (type, chunk_idx) -> mask of lanes that exist\n",
    "\n",
    "    # Special constant-0 source for unconnected pins\n",
    "    CONST_ZERO = '__CONST_ZERO__'\n",
    "    \n",
    "    for t, lst in type_to_insts.items():\n",
    "        for lane, iname in enumerate(lst):\n",
    "            chunk_idx = lane // 64\n",
    "            lane_in_chunk = lane % 64\n",
    "            type_chunk_active_mask[(t, chunk_idx)] |= (1 << lane_in_chunk)\n",
    "            # determine required pins\n",
    "            if t in BIN_OP:\n",
    "                for pin in ('A', 'B'):\n",
    "                    if pin not in pin_wires[iname]:\n",
    "                        # Use constant 0 for unconnected pins (graceful degradation)\n",
    "                        src = CONST_ZERO\n",
    "                    else:\n",
    "                        src = pin_wires[iname][pin]\n",
    "                    masks[(t, chunk_idx, pin, src)] |= (1 << lane_in_chunk)\n",
    "            else:  # unary: NOT\n",
    "                if 'A' not in pin_wires[iname]:\n",
    "                    # Use constant 0 for unconnected pins (graceful degradation)\n",
    "                    src = CONST_ZERO\n",
    "                else:\n",
    "                    src = pin_wires[iname]['A']\n",
    "                masks[(t, chunk_idx, 'A', src)] |= (1 << lane_in_chunk)\n",
    "\n",
    "    # Unique source tokens that appear anywhere\n",
    "    sources = sorted({src for (_, _, _, src) in masks.keys()})\n",
    "\n",
    "    # Build a small resolver to C-expr that yields a 0/1 value for a source token\n",
    "    def bit_expr_0_1(src, state_var='s'):\n",
    "        # constant zero for unconnected pins?\n",
    "        if src == CONST_ZERO:\n",
    "            return '0u'\n",
    "        # input bit?\n",
    "        if is_bit(src):\n",
    "            base, idx = parse_bit(src)\n",
    "            if base in inputs:\n",
    "                # ((A >> (idx-1)) & 1u)\n",
    "                return f'(({c_ident(base)} >> {idx-1}) & 1u)'\n",
    "        # scalar input?\n",
    "        if src in inputs and inputs[src].width == 1:\n",
    "            return f'({c_ident(src)} & 1u)'\n",
    "        # instance output?\n",
    "        if is_inst_pin(src):\n",
    "            iname, pin = split_inst_pin(src)\n",
    "            if pin != 'O':\n",
    "                # only outputs are read as sources\n",
    "                raise ValueError(f\"Unexpected non-output pin as source: {src}\")\n",
    "            t, chunk_idx, lane_in_chunk = inst_lane[iname]\n",
    "            return f'(({state_var}.{c_ident(t)}_O_{chunk_idx} >> {lane_in_chunk}) & 1u)'\n",
    "        # top-level output as source is unusual; if someone did it, treat like input error\n",
    "        raise ValueError(f'Unrecognized source token: {src}')\n",
    "\n",
    "    # ---------- emit C ----------\n",
    "    out = []\n",
    "    W = out.append\n",
    "\n",
    "    W('#include <stdint.h>')\n",
    "    W('#include <stdio.h>')\n",
    "    W('')\n",
    "    W(f'// Auto-generated bit-packed registered simulator for {component.name}')\n",
    "    W('// Each gate family packs up to 64 instances into a 64-bit lane vector.')\n",
    "    W('// Next state is computed from previous state and current inputs (2-phase update).')\n",
    "    W('')\n",
    "\n",
    "    # State struct: one or more 64-bit vectors per gate type (chunks)\n",
    "    W('typedef struct {')\n",
    "    for t in type_to_insts:\n",
    "        num_chunks = type_chunks[t]\n",
    "        for chunk_idx in range(num_chunks):\n",
    "            W(f'    uint64_t {c_ident(t)}_O_{chunk_idx};  // chunk {chunk_idx} of {t} outputs')\n",
    "    W('} State;')\n",
    "    W('')\n",
    "\n",
    "    # tick signature: pass each input port as uint64_t (lower width bits used)\n",
    "    params = ['State s']\n",
    "    for p in component.inputs:\n",
    "        params.append(f'uint64_t {c_ident(p.name)}')\n",
    "    W(f'static inline State tick({\", \".join(params)})' + ' {')\n",
    "    W('    State n = s;')\n",
    "    W('')\n",
    "\n",
    "    # For each gate type and chunk, build input vectors from masks\n",
    "    # Use branchless selection: vec |= (-(bit)) & MASK\n",
    "    for t, inst_list in type_to_insts.items():\n",
    "        num_chunks = type_chunks[t]\n",
    "        for chunk_idx in range(num_chunks):\n",
    "            active_mask = type_chunk_active_mask[(t, chunk_idx)]\n",
    "            if t in BIN_OP:\n",
    "                for pin in ('A', 'B'):\n",
    "                    W(f'    uint64_t {c_ident(t)}_{chunk_idx}_{pin} = 0ull;')\n",
    "                    for src in sources:\n",
    "                        m = masks.get((t, chunk_idx, pin, src), 0)\n",
    "                        if m == 0:\n",
    "                            continue\n",
    "                        bexpr = bit_expr_0_1(src, state_var='s')\n",
    "                        W(f'    {c_ident(t)}_{chunk_idx}_{pin} |= ((uint64_t)-( {bexpr} )) & 0x{m:016x}ull;')\n",
    "                # Compute next outputs\n",
    "                if BIN_OP[t] is None:\n",
    "                    # NAND/NOR\n",
    "                    if t == 'NAND':\n",
    "                        W(f'    n.{c_ident(t)}_O_{chunk_idx} = ~({c_ident(t)}_{chunk_idx}_A & {c_ident(t)}_{chunk_idx}_B) & 0x{active_mask:016x}ull;')\n",
    "                    elif t == 'NOR':\n",
    "                        W(f'    n.{c_ident(t)}_O_{chunk_idx} = ~({c_ident(t)}_{chunk_idx}_A | {c_ident(t)}_{chunk_idx}_B) & 0x{active_mask:016x}ull;')\n",
    "                    else:\n",
    "                        raise AssertionError('Unhandled BIN_OP None case')\n",
    "                else:\n",
    "                    op = BIN_OP[t]\n",
    "                    W(f'    n.{c_ident(t)}_O_{chunk_idx} = ({c_ident(t)}_{chunk_idx}_A {op} {c_ident(t)}_{chunk_idx}_B) & 0x{active_mask:016x}ull;')\n",
    "            else:\n",
    "                # unary NOT\n",
    "                W(f'    uint64_t {c_ident(t)}_{chunk_idx}_A = 0ull;')\n",
    "                for src in sources:\n",
    "                    m = masks.get((t, chunk_idx, 'A', src), 0)\n",
    "                    if m == 0:\n",
    "                        continue\n",
    "                    bexpr = bit_expr_0_1(src, state_var='s')\n",
    "                    W(f'    {c_ident(t)}_{chunk_idx}_A |= ((uint64_t)-( {bexpr} )) & 0x{m:016x}ull;')\n",
    "                W(f'    n.{c_ident(t)}_O_{chunk_idx} = ~({c_ident(t)}_{chunk_idx}_A) & 0x{active_mask:016x}ull;')\n",
    "            W('')\n",
    "\n",
    "    W('    return n;')\n",
    "    W('}')\n",
    "    W('')\n",
    "\n",
    "    # main: scanf-driven demo (fast enough for interactivity; for benchmarks, drive from arrays)\n",
    "    W('int main(void) {')\n",
    "    W('    State s = {0};')\n",
    "    for p in component.inputs:\n",
    "        W(f'    unsigned long long {c_ident(p.name)} = 0ull;')\n",
    "    # Read/print loop\n",
    "    W('    while (1) {')\n",
    "    # Prompt\n",
    "    W('        printf(\"Enter inputs: ' + ' '.join([p.name for p in component.inputs]) + '\\\\n\");')\n",
    "    fmt = ' '.join(['%llu' for _ in component.inputs])\n",
    "    args = ', '.join(['&' + c_ident(p.name) for p in component.inputs])\n",
    "    W(f'        if (scanf(\"{fmt}\", {args}) != {len(component.inputs)}) break;')\n",
    "    # Tick\n",
    "    tick_args = ', '.join(['s'] + [c_ident(p.name) for p in component.inputs])\n",
    "    W(f'        s = tick({tick_args});')\n",
    "    W('')\n",
    "    # Build and print outputs from current state s\n",
    "    for p in component.outputs:\n",
    "        if p.width == 1:\n",
    "            # Output bit source\n",
    "            key = f'{p.name}[1]'\n",
    "            if key not in out_src and p.name in out_src:\n",
    "                key = p.name  # rare scalar name\n",
    "            src = out_src.get(key)\n",
    "            if src is None:\n",
    "                raise ValueError(f'No driver for output {p.name}')\n",
    "            # compute bit\n",
    "            if is_bit(src):\n",
    "                base, idx = parse_bit(src)\n",
    "                if base not in inputs:\n",
    "                    raise ValueError(f'Output {p.name} reads unknown bit source {src}')\n",
    "                bexpr = f'(({c_ident(base)} >> {idx-1}) & 1u)'\n",
    "                W(f'        unsigned long long {c_ident(p.name)}_val = {bexpr};')\n",
    "            elif is_inst_pin(src):\n",
    "                iname, pin = split_inst_pin(src)\n",
    "                if pin != 'O':\n",
    "                    raise ValueError(f'Output {p.name} cannot read non-output pin {src}')\n",
    "                t, chunk_idx, lane_in_chunk = inst_lane[iname]\n",
    "                W(f'        unsigned long long {c_ident(p.name)}_val = (unsigned long long)((s.{c_ident(t)}_O_{chunk_idx} >> {lane_in_chunk}) & 1u);')\n",
    "            else:\n",
    "                # scalar input\n",
    "                if src in inputs and inputs[src].width == 1:\n",
    "                    W(f'        unsigned long long {c_ident(p.name)}_val = (unsigned long long)({c_ident(src)} & 1u);')\n",
    "                else:\n",
    "                    raise ValueError(f'Output {p.name} has unsupported driver {src}')\n",
    "        else:\n",
    "            # multi-bit: reconstruct integer from bit drivers\n",
    "            terms = []\n",
    "            for i in range(1, p.width + 1):\n",
    "                key = f'{p.name}[{i}]'\n",
    "                src = out_src.get(key)\n",
    "                if src is None:\n",
    "                    raise ValueError(f'No driver for output {key}')\n",
    "                if is_bit(src):\n",
    "                    base, idx = parse_bit(src)\n",
    "                    if base not in inputs:\n",
    "                        raise ValueError(f'Output {key} reads unknown bit source {src}')\n",
    "                    term = f'((( {c_ident(base)} >> {idx-1}) & 1ull) << {i-1})'\n",
    "                elif is_inst_pin(src):\n",
    "                    iname, pin = split_inst_pin(src)\n",
    "                    if pin != 'O':\n",
    "                        raise ValueError(f'Output {key} cannot read non-output pin {src}')\n",
    "                    t, chunk_idx, lane_in_chunk = inst_lane[iname]\n",
    "                    term = f'(( (s.{c_ident(t)}_O_{chunk_idx} >> {lane_in_chunk}) & 1ull) << {i-1})'\n",
    "                else:\n",
    "                    # scalar input routed to a bit\n",
    "                    if src in inputs and inputs[src].width == 1:\n",
    "                        term = f'((( {c_ident(src)} & 1ull) ) << {i-1})'\n",
    "                    else:\n",
    "                        raise ValueError(f'Output {key} has unsupported driver {src}')\n",
    "                terms.append(term)\n",
    "            W(f'        unsigned long long {c_ident(p.name)}_val = ' + ' | '.join(terms) + ';')\n",
    "        # print line per output\n",
    "        W(f'        printf(\"{p.name}=%llu\\\\n\", {c_ident(p.name)}_val);')\n",
    "    W('    }')\n",
    "    W('    return 0;')\n",
    "    W('}')\n",
    "    return '\\n'.join(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a122e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f08359e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before flattening:\n",
      "  Instances: 16\n",
      "  Connections: 65\n",
      "  Instance types: {'FullAdder'}\n",
      "\n",
      "After flattening:\n",
      "  Instances: 80\n",
      "  Connections: 177\n",
      "  Instance types: {'OR', 'XOR', 'AND'}\n",
      "\n",
      "Sample connections (first 10):\n",
      "  A[1] -> fa1_x1.A\n",
      "  B[1] -> fa1_x1.B\n",
      "  A[1] -> fa1_a1.A\n",
      "  B[1] -> fa1_a1.B\n",
      "  fa1_x1.O -> fa1_x2.A\n",
      "  Cin -> fa1_x2.B\n",
      "  fa1_x1.O -> fa1_a2.A\n",
      "  Cin -> fa1_a2.B\n",
      "  fa1_a1.O -> fa1_o1.A\n",
      "  fa1_a2.O -> fa1_o1.B\n"
     ]
    }
   ],
   "source": [
    "search_paths = [Path.cwd() / \"SHDL_components\"]\n",
    "shdl_parser = SHDLParser(search_paths)\n",
    "\n",
    "\n",
    "file = Path(\"adder16.shdl\")\n",
    "component = shdl_parser.parse_file(file)\n",
    "\n",
    "print(f\"Before flattening:\")\n",
    "print(f\"  Instances: {len(component.instances)}\")\n",
    "print(f\"  Connections: {len(component.connections)}\")\n",
    "print(f\"  Instance types: {set(i.component_type for i in component.instances)}\")\n",
    "\n",
    "component = shdl_parser.flatten_all_levels(component)\n",
    "\n",
    "print(f\"\\nAfter flattening:\")\n",
    "print(f\"  Instances: {len(component.instances)}\")\n",
    "print(f\"  Connections: {len(component.connections)}\")\n",
    "print(f\"  Instance types: {set(i.component_type for i in component.instances)}\")\n",
    "\n",
    "# Sample some connections\n",
    "print(f\"\\nSample connections (first 10):\")\n",
    "for src, dst in component.connections[:10]:\n",
    "    print(f\"  {src} -> {dst}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "051f36f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully generated cpu16.c (14354 bytes)\n",
      "  - 80 instances\n",
      "  - 177 connections\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    c_code = generate_c_bitpacked(component)\n",
    "    with open(\"adder16.c\", \"w\") as f:\n",
    "        f.write(c_code)\n",
    "    print(f\"✓ Successfully generated cpu16.c ({len(c_code)} bytes)\")\n",
    "    print(f\"  - {len(component.instances)} instances\")\n",
    "    print(f\"  - {len(component.connections)} connections\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428d3daa",
   "metadata": {},
   "source": [
    "gcc -O3 -march=native -flto -fomit-frame-pointer -pipe adder16.c -o adder16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SHDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
